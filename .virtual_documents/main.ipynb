import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn
import seaborn as sns
from sklearn import linear_model as lm
from sklearn.model_selection import train_test_split
import os
import re
import ta
import mplfinance as mpf

import torch


data = [[1, 2], [3, 4]]
x_data = torch.tensor(data)


x_ones = torch.ones_like(x_data) # retains the properties of x_data
print(f"Ones Tensor: \n {x_ones} \n")

x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data
print(f"Random Tensor: \n {x_rand} \n")


# import resnet model 
from torchvision.models import resnet18, ResNet18_Weights
model = resnet18(weights=ResNet18_Weights.DEFAULT)


# set the data and labels, which are tensors 
data = torch.rand(1, 3, 64, 64)
labels = torch.rand(1, 1000)


# set prediction to the value of the model called on the data 
prediction = model(data)

# loss is defined as the sum of the prediction minus the labels 
loss = (prediction - labels).sum()


loss.backward() # backward propagation 
optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9) # we load an optimizer, in this case SGD with a learning rate of 0.01 and momentum of 0.9. We register all the parameters of the model in the optimizer.
optim.step() # gradient descent 



