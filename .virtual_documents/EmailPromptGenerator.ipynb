


!pip install transformers torch

from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# Load pre-trained model and tokenizer
model = GPT2LMHeadModel.from_pretrained('gpt2')
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

# Set the model to evaluation mode
model.eval()


def generate_email(prompt, max_length=150):
    # Encode the prompt
    encoded_input = tokenizer.encode(prompt, return_tensors='pt')
    # Create attention mask (1 for real tokens, 0 for padding)
    attention_mask = torch.ones(encoded_input.shape, dtype=torch.long)
    
    # Generate output sequence with updated parameters
    output_sequences = model.generate(
        input_ids=encoded_input,
        attention_mask=attention_mask,
        max_length=max_length,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        repetition_penalty=2.5,
        top_p=0.92,
        temperature=0.85,
        do_sample=True,
        top_k=50,
        pad_token_id=tokenizer.eos_token_id,
        # Adjust these as necessary
        num_beams=1,  # Set to >1 if using early_stopping
        early_stopping=False  # Remove or set to True if num_beams > 1
    )
    
    return tokenizer.decode(output_sequences[0], skip_special_tokens=True)


# Example prompt 1
prompt = "Subject: Quarterly Job Performance Review\nDear [Name],\nI would like to discuss"
generated_email = generate_email(prompt)
print(generated_email)



# Example prompt 1
prompt = "Subject: Request for Pay Raise \nDear [Employee Name],\nI would like to discuss"
generated_email = generate_email(prompt)
print(generated_email)



