{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd296246-f1ed-44ef-b202-6c985156110b",
   "metadata": {},
   "source": [
    "# Basic Operations of PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee3f33-a5cc-481f-879c-b0bb42727cde",
   "metadata": {},
   "source": [
    "## PyTorch Basics ##\n",
    "This notebook introduces basic operations in PyTorch.  \n",
    "I have put notes on tensor creation, operations, and gradient computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00fec2fc-cf5c-4b81-90c0-dbea9a0dd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52f761-0c86-48dd-a95c-b881c3f0c5e7",
   "metadata": {},
   "source": [
    "# Creating Tensors: ## \n",
    "Tensors are the core components in PyTorch used for all computational operations. \n",
    "Here's how to create and manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d1609d2-97be-4c69-a159-5ea5402b446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Tensor:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Random Tensor:\n",
      "tensor([[0.7147, 0.1476, 0.6963],\n",
      "        [0.3563, 0.0016, 0.4193]])\n",
      "\n",
      "Tensor from List:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of size 2x3 filled with zeros\n",
    "zeros = torch.zeros(2, 3)\n",
    "print(\"Zero Tensor:\")\n",
    "print(zeros)\n",
    "\n",
    "# Create a tensor filled with random values\n",
    "random_tensor = torch.rand(2, 3)\n",
    "print(\"\\nRandom Tensor:\")\n",
    "print(random_tensor)\n",
    "\n",
    "# Create a tensor from a Python list\n",
    "list_tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"\\nTensor from List:\")\n",
    "print(list_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9af00d-fba4-4cf5-a439-38d834ee3e0b",
   "metadata": {},
   "source": [
    "## Operations on Tensors ##\n",
    "We can perform a variety of operations on tensors including arithmetic, matrix operations, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0958753-ff4b-499f-837e-671756aab686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Zero and Random Tensor:\n",
      "tensor([[0.7147, 0.1476, 0.6963],\n",
      "        [0.3563, 0.0016, 0.4193]])\n",
      "\n",
      "Element-wise Multiplication:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Matrix Multiplication:\n",
      "tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "sum_tensor = torch.add(zeros, random_tensor)\n",
    "print(\"Sum of Zero and Random Tensor:\")\n",
    "print(sum_tensor)\n",
    "\n",
    "# Element-wise multiplication\n",
    "mul_tensor = zeros * random_tensor\n",
    "print(\"\\nElement-wise Multiplication:\")\n",
    "print(mul_tensor)\n",
    "\n",
    "# Matrix multiplication\n",
    "mat_mul_tensor = torch.matmul(list_tensor, torch.tensor([[2, 0], [0, 2]]))\n",
    "print(\"\\nMatrix Multiplication:\")\n",
    "print(mat_mul_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498f541-dc5b-452d-a0bb-54d3f7caeea8",
   "metadata": {},
   "source": [
    "## Autograd ##\n",
    "`Autograd` is PyTorch's automatic differentiation engine that powers neural network training. Here's how to use it with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b58b4e1-2f77-4b42-bee8-d0bdb9bdee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of y with respect to x:\n",
      "tensor([3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors for gradient computation\n",
    "x = torch.rand(3, requires_grad=True)\n",
    "y = 3*x + 2\n",
    "\n",
    "# Compute gradients\n",
    "y.backward(torch.ones_like(x))\n",
    "print(\"Gradient of y with respect to x:\")\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c7c01-493f-4b21-990e-bfb41ae15857",
   "metadata": {},
   "source": [
    "## Reshaping Tensors ##\n",
    "Reshaping tensors is a common operation, especially when preparing data for different types of neural network layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf36cb9d-d46d-4c74-8a6b-a9c7f3c516b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor:\n",
      "tensor([[0.8593, 0.3608, 0.5692, 0.7866],\n",
      "        [0.5702, 0.3318, 0.1502, 0.4709],\n",
      "        [0.6413, 0.7726, 0.2800, 0.7369],\n",
      "        [0.6210, 0.9453, 0.5311, 0.9798]])\n",
      "\n",
      "Reshaped Tensor:\n",
      "tensor([[0.8593, 0.3608, 0.5692, 0.7866, 0.5702, 0.3318, 0.1502, 0.4709],\n",
      "        [0.6413, 0.7726, 0.2800, 0.7369, 0.6210, 0.9453, 0.5311, 0.9798]])\n",
      "\n",
      "Flattened Tensor:\n",
      "tensor([0.8593, 0.3608, 0.5692, 0.7866, 0.5702, 0.3318, 0.1502, 0.4709, 0.6413,\n",
      "        0.7726, 0.2800, 0.7369, 0.6210, 0.9453, 0.5311, 0.9798])\n"
     ]
    }
   ],
   "source": [
    "# Reshape tensor to different dimensions\n",
    "original_tensor = torch.rand(4, 4)\n",
    "reshaped_tensor = original_tensor.view(2, 8)\n",
    "print(\"Original Tensor:\")\n",
    "print(original_tensor)\n",
    "print(\"\\nReshaped Tensor:\")\n",
    "print(reshaped_tensor)\n",
    "\n",
    "# Flatten tensor\n",
    "flat_tensor = original_tensor.flatten()\n",
    "print(\"\\nFlattened Tensor:\")\n",
    "print(flat_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6c599-9300-4887-bdb8-4933b5c1b638",
   "metadata": {},
   "source": [
    "## Indexing and Slicing ##\n",
    "Indexing and slicing are important for accessing sub-parts of tensors, which is particularly useful during model training to select specific samples, features, or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25c1243-f768-4974-91c7-8acb97eb2ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Row of Original Tensor:\n",
      "tensor([0.5702, 0.3318, 0.1502, 0.4709])\n",
      "\n",
      "Third Column of Original Tensor:\n",
      "tensor([0.5692, 0.1502, 0.2800, 0.5311])\n",
      "\n",
      "Upper Left Quarter of Tensor:\n",
      "tensor([[0.8593, 0.3608],\n",
      "        [0.5702, 0.3318]])\n"
     ]
    }
   ],
   "source": [
    "# Index into tensor to get a row\n",
    "second_row = original_tensor[1]\n",
    "print(\"Second Row of Original Tensor:\")\n",
    "print(second_row)\n",
    "\n",
    "# Slice tensor to get a specific column\n",
    "third_column = original_tensor[:, 2]\n",
    "print(\"\\nThird Column of Original Tensor:\")\n",
    "print(third_column)\n",
    "\n",
    "# Complex slicing\n",
    "upper_left_quarter = original_tensor[:2, :2]\n",
    "print(\"\\nUpper Left Quarter of Tensor:\")\n",
    "print(upper_left_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db56f93-757c-4917-9a3a-d208e0fb802f",
   "metadata": {},
   "source": [
    "## Concatenation and Stacking ##\n",
    "Concatenating and stacking tensors are crucial when combining data from different sources or for building complex network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485a6a36-2d9b-459a-9aac-c3ed8bb20149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Tensor along Dimension 0:\n",
      "tensor([[0.8593, 0.3608, 0.5692, 0.7866],\n",
      "        [0.5702, 0.3318, 0.1502, 0.4709],\n",
      "        [0.6413, 0.7726, 0.2800, 0.7369],\n",
      "        [0.6210, 0.9453, 0.5311, 0.9798],\n",
      "        [0.8593, 0.3608, 0.5692, 0.7866],\n",
      "        [0.5702, 0.3318, 0.1502, 0.4709],\n",
      "        [0.6413, 0.7726, 0.2800, 0.7369],\n",
      "        [0.6210, 0.9453, 0.5311, 0.9798]])\n",
      "\n",
      "Stacked Tensor along New Dimension:\n",
      "tensor([[[0.8593, 0.3608, 0.5692, 0.7866],\n",
      "         [0.5702, 0.3318, 0.1502, 0.4709],\n",
      "         [0.6413, 0.7726, 0.2800, 0.7369],\n",
      "         [0.6210, 0.9453, 0.5311, 0.9798]],\n",
      "\n",
      "        [[0.8593, 0.3608, 0.5692, 0.7866],\n",
      "         [0.5702, 0.3318, 0.1502, 0.4709],\n",
      "         [0.6413, 0.7726, 0.2800, 0.7369],\n",
      "         [0.6210, 0.9453, 0.5311, 0.9798]]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate tensors along the first dimension\n",
    "concatenated_tensor = torch.cat([original_tensor, original_tensor], dim=0)\n",
    "print(\"Concatenated Tensor along Dimension 0:\")\n",
    "print(concatenated_tensor)\n",
    "\n",
    "# Stack tensors along a new dimension\n",
    "stacked_tensor = torch.stack([original_tensor, original_tensor], dim=0)\n",
    "print(\"\\nStacked Tensor along New Dimension:\")\n",
    "print(stacked_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84636bec-d77d-4f7d-93cc-bc3198bd92e0",
   "metadata": {},
   "source": [
    "## More Complex Operations ##\n",
    "PyTorch supports more complex operations such as tensor splitting, tensor tiling (repeating), and applying custom functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b5ded9b-410c-4249-9059-720588b9e882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors Split into Two Rows each:\n",
      "tensor([[0.8593, 0.3608, 0.5692, 0.7866],\n",
      "        [0.5702, 0.3318, 0.1502, 0.4709]])\n",
      "tensor([[0.6413, 0.7726, 0.2800, 0.7369],\n",
      "        [0.6210, 0.9453, 0.5311, 0.9798]])\n",
      "\n",
      "Repeated Tensor:\n",
      "tensor([[0.8593, 0.3608, 0.5692, 0.7866, 0.8593, 0.3608, 0.5692, 0.7866],\n",
      "        [0.5702, 0.3318, 0.1502, 0.4709, 0.5702, 0.3318, 0.1502, 0.4709],\n",
      "        [0.6413, 0.7726, 0.2800, 0.7369, 0.6413, 0.7726, 0.2800, 0.7369],\n",
      "        [0.6210, 0.9453, 0.5311, 0.9798, 0.6210, 0.9453, 0.5311, 0.9798],\n",
      "        [0.8593, 0.3608, 0.5692, 0.7866, 0.8593, 0.3608, 0.5692, 0.7866],\n",
      "        [0.5702, 0.3318, 0.1502, 0.4709, 0.5702, 0.3318, 0.1502, 0.4709],\n",
      "        [0.6413, 0.7726, 0.2800, 0.7369, 0.6413, 0.7726, 0.2800, 0.7369],\n",
      "        [0.6210, 0.9453, 0.5311, 0.9798, 0.6210, 0.9453, 0.5311, 0.9798]])\n",
      "\n",
      "Tensor after Applying Custom Function:\n",
      "tensor([[3.4570, 1.8519, 2.4625, 3.1921],\n",
      "        [2.4654, 1.7738, 1.3229, 2.1635],\n",
      "        [2.6939, 3.1422, 1.6385, 3.0167],\n",
      "        [2.6277, 3.7840, 2.3441, 3.9197]])\n"
     ]
    }
   ],
   "source": [
    "# Split tensor into chunks\n",
    "split_tensors = torch.split(original_tensor, 2)\n",
    "print(\"Tensors Split into Two Rows each:\")\n",
    "for t in split_tensors:\n",
    "    print(t)\n",
    "\n",
    "# Repeat tensor\n",
    "tiled_tensor = original_tensor.repeat(2, 2)\n",
    "print(\"\\nRepeated Tensor:\")\n",
    "print(tiled_tensor)\n",
    "\n",
    "# Apply a custom function element-wise\n",
    "def custom_function(x):\n",
    "    return x ** 2 + 2*x + 1\n",
    "\n",
    "custom_tensor = custom_function(original_tensor)\n",
    "print(\"\\nTensor after Applying Custom Function:\")\n",
    "print(custom_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
